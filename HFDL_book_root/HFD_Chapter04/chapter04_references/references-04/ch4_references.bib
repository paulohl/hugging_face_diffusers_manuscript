@Article{Radford2021a,
  author        = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  journal       = {International Conference on Machine Learning (ICML)},
  title         = {Learning Transferable Visual Models From Natural Language Supervision},
  year          = {2021},
  note          = {arXiv:2103.00020},
  abstract      = {State-Of-The-Art Computer Vision Systems Are Trained To Predict A Fixed Set Of Predetermined Object Categories. This Restricted Form Of Supervision Limits Their Generality And Usability Since Additional Labeled Data Is Needed To Specify Any Other Visual Concept. Learning Directly From Raw Text About Images Is A Promising Alternative Which Leverages A Much Broader Source Of Supervision. We Demonstrate That The Simple Pre-Training Task Of Predicting Which Caption Goes With Which Image Is An Efficient And Scalable Way To Learn Sota Image Representations From Scratch On A Dataset Of 400 Million (image, Text) Pairs Collected From The Internet. After Pre-Training, Natural Language Is Used To Reference Learned Visual Concepts (or Describe New Ones) Enabling Zero-Shot Transfer Of The Model To Downstream Tasks. We Study The Performance Of This Approach By Benchmarking On Over 30 Different Existing Computer Vision Datasets, Spanning Tasks Such As Ocr, Action Recognition In Videos, Geo-Localization, And Many Types Of Fine-Grained Object Classification. The Model Transfers Non-Trivially To Most Tasks And Is Often Competitive With A Fully Supervised Baseline Without The Need For Any Dataset Specific Training. For Instance, We Match The Accuracy Of The Original Resnet-50 On Imagenet Zero-Shot Without Needing To Use Any Of The 1.28 Million Training Examples It Was Trained On.},
  comment-paulo = {We Release Our Code And Pre-Trained Model Weights At This Https Url. : https://github.com/OpenAI/CLIP},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2103.00020},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher     = {arXiv},
  url           = {https://arxiv.org/abs/2103.00020},
}

@Article{Gao2020a,
  author    = {Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal   = {ACL},
  title     = {Making Pre-trained Language Models Better Few-shot Learners},
  year      = {2020},
  note      = {arXiv:2012.15723},
  abstract  = {The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF--better few-shot fine-tuning of language models--a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30% absolute improvement, and 11% on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2012.15723},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2012.15723},
}

@Article{Zhao2021a,
  author    = {Zhao, Tony Z. and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  journal   = {ICLR},
  title     = {Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  year      = {2021},
  note      = {arxiv.org/abs/2102.09690},
  abstract  = {GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples. We show that this type of few-shot learning can be unstable: the choice of prompt format, training examples, and even the order of the training examples can cause accuracy to vary from near chance to near state-of-the-art. We demonstrate that this instability arises from the bias of language models towards predicting certain answers, e.g., those that are placed near the end of the prompt or are common in the pre-training data. To mitigate this, we first estimate the model's bias towards each answer by asking for its prediction when given the training prompt and a content-free test input such as "N/A". We then fit calibration parameters that cause the prediction for this input to be uniform across answers. On a diverse set of tasks, this contextual calibration procedure substantially improves GPT-3 and GPT-2's average accuracy (up to 30.0% absolute) and reduces variance across different choices of the prompt.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2102.09690},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2102.09690},
}

@Article{Liu2022a,
  author    = {Liu, Alisa and Swayamdipta, Swabha and Smith, Noah A. and Choi, Yejin},
  journal   = {arXiv preprint arXiv:2201.05955},
  title     = {WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation},
  year      = {2022},
  note      = {arXiv:2201.05955},
  abstract  = {A recurring challenge of crowdsourcing NLP datasets at scale is that human writers often rely on repetitive patterns when crafting examples, leading to a lack of linguistic diversity. We introduce a novel approach for dataset creation based on worker and AI collaboration, which brings together the generative strength of language models and the evaluative strength of humans. Starting with an existing dataset, MultiNLI for natural language inference (NLI), our approach uses dataset cartography to automatically identify examples that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose new examples with similar patterns. Machine generated examples are then automatically filtered, and finally revised and labeled by human crowdworkers. The resulting dataset, WANLI, consists of 107,885 NLI examples and presents unique empirical strengths over existing NLI datasets. Remarkably, training a model on WANLI improves performance on eight out-of-domain test sets we consider, including by 11% on HANS and 9% on Adversarial NLI, compared to training on the 4x larger MultiNLI. Moreover, it continues to be more effective than MultiNLI augmented with other NLI datasets. Our results demonstrate the promise of leveraging natural language generation techniques and re-imagining the role of humans in the dataset creation process.},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.2201.05955},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2201.05955},
}

@InProceedings{Bommasani2021a,
  author        = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and R{\'{e}}, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramer, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  booktitle     = {Stanford Center for Research on Foundation Models},
  title         = {On the Opportunities and Risks of Foundation Models},
  year          = {2021},
  note          = {arXiv:2108.07258},
  publisher     = {arXiv},
  abstract      = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
  comment-paulo = {Authored by the Center for Research on Foundation Models (CRFM) at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Report page with citation guidelines: this https URL: https://crfm.stanford.edu/report.html},
  copyright     = {Creative Commons Attribution 4.0 International},
  doi           = {10.48550/ARXIV.2108.07258},
  keywords      = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  url           = {https://arxiv.org/abs/2108.07258},
}

@Article{Ganguli2023a,
  author    = {Deep Ganguli and Peter Hase and others},
  journal   = {arXiv preprint arXiv:2305.16328},
  title     = {Semantic Composition in Visually Grounded Language Models},
  year      = {2023},
  note      = {arXiv:2305.16328},
  abstract  = {What is sentence meaning and its ideal representation? Much of the expressive power of human language derives from semantic composition, the mind's ability to represent meaning hierarchically and relationally over constituents. At the same time, much sentential meaning is outside the text and requires grounding in sensory, motor, and experiential modalities to be adequately learned. Although large language models display considerable compositional ability, recent work shows that visually-grounded language models drastically fail to represent compositional structure. In this thesis, we explore whether and how models compose visually grounded semantics, and how we might improve their ability to do so.
Specifically, we introduce 
1) WinogroundVQA, a new compositional visual question answering benchmark, 
2) Syntactic Neural Module Distillation, a measure of compositional ability in sentence embedding models, 
3) Causal Tracing for Image Captioning Models to locate neural representations vital for vision-language composition, 
4) Syntactic MeanPool to inject a compositional inductive bias into sentence embeddings, and 
5) Cross-modal Attention Congruence Regularization, a self-supervised objective function for vision-language relation alignment. 
We close by discussing connections of our work to neuroscience, psycholinguistics, formal semantics, and philosophy.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2305.16328},
  eprint    = {2305.16328},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2305.16328},
}

@Article{Ouyang2022a,
  author    = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  journal   = {NeurIPS},
  title     = {Training language models to follow instructions with human feedback},
  year      = {2022},
  note      = {arXiv:2203.02155},
  abstract  = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2203.02155},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2203.02155},
}

@Article{Perez2022a,
  author    = {Perez, Ethan and Ringer, Sam and Lukosiute, K. and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and Jones, Andy and Chen, Anna and Mann, Ben and Israel, Brian and Seethor, Bryan and McKinnon, Cameron and Olah, Christopher and Yan, Da and Amodei, Daniela and Amodei, Dario and Drain, Dawn and Li, Dustin and Tran-Johnson, Eli and Khundadze, Guro and Kernion, Jackson and Landis, James and Kerr, Jamie and Mueller, Jared and Hyun, Jeeyoon and Landau, Joshua and Ndousse, Kamal and Goldberg, Landon and Lovitt, Liane and Lucas, Martin and Sellitto, Michael and Zhang, Miranda and Kingsland, Neerav and Elhage, Nelson and Joseph, Nicholas and Mercado, Noem{\'{i}} and DasSarma, Nova and Rausch, Oliver and Larson, Robin and McCandlish, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Lanham, Tamera and Telleen-Lawton, Timothy and Brown, Tom and Henighan, Tom and Hume, Tristan and Bai, Yuntao and Hatfield-Dodds, Zac and Clark, Jack and Bowman, Samuel R. and Askell, Amanda and Grosse, Roger and Hernandez, Danny and Ganguli, Deep and Hubinger, Evan and Schiefer, Nicholas and Kaplan, Jareds},
  journal   = {Transactions of the Association for Computational Linguistics},
  title     = {Discovering Language Model Behaviors with Model-Written Evaluations},
  year      = {2022},
  note      = {arXiv:2212.09251},
  abstract  = {As language models (LMs) scale, they develop many novel behaviors, good and bad, exacerbating the need to evaluate how they behave. Prior work creates evaluations with crowdwork (which is time-consuming and expensive) or existing data sources (which are not always available). Here, we automatically generate evaluations with LMs. We explore approaches with varying amounts of human effort, from instructing LMs to write yes/no questions to making complex Winogender schemas with multiple stages of LM-based generation and filtering. Crowdworkers rate the examples as highly relevant and agree with 90-100% of labels, sometimes more so than corresponding human-written datasets. We generate 154 datasets and discover new cases of inverse scaling where LMs get worse with size. Larger LMs repeat back a dialog user's preferred answer ("sycophancy") and express greater desire to pursue concerning goals like resource acquisition and goal preservation. We also find some of the first examples of inverse scaling in RL from Human Feedback (RLHF), where more RLHF makes LMs worse. For example, RLHF makes LMs express stronger political views (on gun rights and immigration) and a greater desire to avoid shut down. Overall, LM-written evaluations are high-quality and let us quickly discover many novel LM behaviors.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2212.09251},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2212.09251},
}

@InProceedings{Rabiner1989a,
  author         = {Rabiner, L. R.},
  title          = {A tutorial on hidden Markov models and selected applications in speech recognition},
  year           = {1989},
  number         = {2},
  organization   = {Proceedings of the IEEE,},
  pages          = {257--286},
  publisher      = {IEEE},
  volume         = {77},
  abstract       = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.},
  doi            = {10.1109/5.18626},
  issn           = {0018-9219},
  journal        = {Proceedings of the IEEE},
  keywords       = {Tutorial,Hidden Markov models,Speech recognition},
  msbib-accessed = {2025-01-07},
}

@Article{Devlin2019a,
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal   = {NAACL-HLT},
  title     = {BERT: Pre-training of deep bidirectional transformers for language understanding},
  year      = {2019},
  note      = {arXiv preprint arXiv:1810.04805.},
  pages     = {4171, 4186},
  booktitle = {Proceedings of the 2019 Conference of the North},
  doi       = {10.18653/v1/n19-1423},
  eprint    = {1810.04805},
  publisher = {Association for Computational Linguistics},
  url       = {https://arxiv.org/abs/1810.04805},
}

@Article{Huang2015a,
  author    = {Huang, Z. and Xu, W. and Yu, K.},
  journal   = {preprint},
  title     = {Bidirectional LSTM-CRF Models for Sequence Tagging},
  year      = {2015},
  note      = {arXiv preprint arXiv:1508.01991.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1508.01991},
  eprint    = {1508.01991},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://doi.org/10.48550/arXiv.1508.01991},
}

@InProceedings{Lafferty2001a,
  author    = {J. Lafferty and A. McCallum and Fernando Pereira},
  booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
  title     = {Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
  year      = {2001},
  address   = {San Francisco, Calif.},
  editor    = {Carla E. Brodley},
  pages     = {282, 289},
  publisher = {Morgan Kaufmann Publishers Inc.},
  series    = {ICML '01},
  acmid     = {655813},
  doi       = {10.5555/645530.655813},
  file      = {:C\:/Users/paulo/OneDrive/Documents/Zinnia_OneDrive_Backup/Research/books/BPB_Publishing/Hugging_Face_Diffusers/HFD_Chapter04-Sequence Labeling with Hugging Face Diffusers/chapter04_references/crf.pdf:PDF},
  isbn      = {1558607781},
  keywords  = {sentence clustering, document summarization, discrete differential evolution algorithm},
  ppn_gvk   = {333238109},
  url       = {https://api.semanticscholar.org/CorpusID:219683473},
}

@Article{Mikolov2013a,
  author        = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  title         = {Efficient estimation of word representations in vector space},
  year          = {2013},
  note          = {arXiv preprint arXiv:1301.3781.},
  abstract      = {We propose two novel model architectures for computing continuous vector
representations of words from very large data sets. The quality of these
representations is measured in a word similarity task, and the results are
compared to the previously best performing techniques based on different types
of neural networks. We observe large improvements in accuracy at much lower
computational cost, i.e. it takes less than a day to learn high quality word
vectors from a 1.6 billion words data set. Furthermore, we show that these
vectors provide state-of-the-art performance on our test set for measuring
syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1301.3781},
  eprint        = {1301.3781},
  keywords      = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher     = {arXiv},
  url           = {https://www.semanticscholar.org/paper/f6b51c8753a871dc94ff32152c00c01e94f90f09},
}

@InProceedings{Pennington2014a,
  author       = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle    = {Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  title        = {Glove: Global vectors for word representation},
  year         = {2014},
  organization = {Conference on empirical methods in natural language processing (EMNLP)},
  pages        = {1532--1543},
  publisher    = {Association for Computational Linguistics},
  doi          = {10.3115/v1/d14-1162},
  url          = {https://aclanthology.org/D14-1162/},
}

@Article{McCallum2005a,
  author    = {McCallum, A.},
  journal   = {Queue},
  title     = {Information extraction: Distilling structured data from unstructured text},
  year      = {2005},
  issn      = {1542-7749},
  month     = nov,
  number    = {9},
  pages     = {48, 57},
  volume    = {3},
  doi       = {10.1145/1105664.1105679},
  publisher = {Association for Computing Machinery (ACM)},
  url       = {https://spawn-queue.acm.org/doi/10.1145/1105664.1105679},
}

@Article{Lample2016a,
  author    = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  journal   = {preprint},
  title     = {Neural architectures for named entity recognition},
  year      = {2016},
  note      = {arXiv preprint arXiv:1603.01360.},
  abstract  = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1603.01360},
  eprint    = {1603.01360},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://doi.org/10.48550/arXiv.1603.01360},
}

@Article{Pang2008a,
  author    = {Pang, Bo and Lee, Lillian},
  journal   = {Foundations and TrendsÂ® in Information Retrieval},
  title     = {Opinion mining and sentiment analysis},
  year      = {2008},
  issn      = {1554-0677},
  number    = {1, 2},
  pages     = {1, 135},
  volume    = {2},
  doi       = {10.1561/1500000011},
  publisher = {Emerald},
}

@InProceedings{Manning2011a,
  author       = {Manning, Christopher D.},
  booktitle    = {Computational Linguistics and Intelligent Text Processing},
  title        = {Part-of-Speech Tagging from 97% to 100%: Is It Time for Some Linguistics?},
  year         = {2011},
  address      = {Berlin, Heidelberg},
  editor       = {Takeo Kanade and Josef Kittler},
  note         = {Description based on publisher supplied metadata and other sources.},
  number       = {v.6608},
  organization = {Computational Linguistics and Intelligent Text Processing},
  pages        = {171, 189},
  publisher    = {Springer-Verlag},
  series       = {CICLing'11},
  abstract     = {. I examine what would be necessary to move part-of-speech tagging performance from its current level of about 97.3% token accuracy (56% sentence accuracy) to close to 100% accuracy. I suggest thatit must still be possible to greatly increase tagging performance and examine some useful improvements that have recently been made to the Stanford Part-of-Speech Tagger. However, an error analysis of some of the remaining errors suggests that there is limited further mileage to be had either from better machine learning or better features in a discriminative sequence classifier. The prospects for further gains from semisupervised learning also seem quite limited. Rather, I suggest and begin to demonstrate that the largest opportunity for further progress comes from improving the taxonomic basis of the linguistic resources from which taggers are trained. That is, from improved descriptive linguistics. However, I conclude by suggesting that there are also limits to this process. The status of some words may not be able to be adequately captured by assigning them to one of a small number of categories. While conventions can be used in such cases to improve tagging consistency, they lack a strong linguistic basis.},
  doi          = {10.1007/978-3-642-19400-9_14},
  isbn         = {9783642194009},
  issn         = {1611-3349},
  numpages     = {19},
  ppn_gvk      = {1672850886},
  url          = {https://nlp.stanford.edu/pubs/CICLing2011-manning-tagging.pdf},
}

@Article{Honnibal2017a,
  author  = {Honnibal, Matthew and Montani, Ines},
  journal = {preprint},
  title   = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
  year    = {2017},
  note    = {To appear.},
  url     = {https://cir.nii.ac.jp/crid/1370021390573874949},
}

@InProceedings{Jagannatha2016a,
  author       = {Jagannatha, Abhyuday and yu, hong},
  booktitle    = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  title        = {Structured prediction models for RNN based sequence labeling in clinical text},
  year         = {2016},
  organization = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages        = {856--865},
  publisher    = {Association for Computational Linguistics},
  doi          = {10.18653/v1/d16-1082},
  eprint       = {1608.00612},
  url          = {https://aclanthology.org/D16-1082/},
}

@Article{Manning2014a,
  author    = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
  journal   = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  title     = {The Stanford CoreNLP Natural Language Processing Toolkit},
  year      = {2014},
  issn      = {0736-587X},
  pages     = {55--60},
  volume    = {2014-June},
  abstract  = {We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.},
  address   = {Stroudsburg, PA},
  booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  doi       = {10.3115/v1/p14-5010},
  editor    = {Ekaterina Kochmar and Kalina Bontcheva and Annie Louis and Jingbo Zhu and Svitlana Volkova and Jordan Boyd-Graber and Bill Byrne},
  isbn      = {9781941643006},
  ppn_gvk   = {1658688589},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P14-5010},
}

@Comment{jabref-meta: databaseType:bibtex;}
