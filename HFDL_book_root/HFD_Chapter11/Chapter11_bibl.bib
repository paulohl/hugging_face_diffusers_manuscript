@Article{Mnih,
  author  = {Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. A. and Veness, J. and Bellemare, M. G. and Hassabis, D.},
  journal = {Nature},
  title   = {Human-level control through deep reinforcement learning},
  number  = {7540},
  pages   = {529, 533},
  volume  = {518},
  doi     = {10.1038/nature14236},
  url     = {https://doi.org/10.1038/nature14236},
}

@Electronic{OpenAI,
  author = {OpenAI},
  note   = {Retrieved from},
  title  = {OpenAI gym retro},
  url    = {https://github.com/openai/retro},
}

@techreport{Mnih2013,
author = {Mnih, V. and Kavukcuoglu, K. and Silver, D. },
title = {Playing Atari with deep reinforcement learning},
year = {2013}
}

@article{Bellemare2013,
author = {Bellemare, M. G. and Naddaf, Y. and Veness, J. and Bowling, M. },
title = {The arcade learning environment: An evaluation platform for general agents},
journal = {Journal of Artificial Intelligence Research},
year = {2013},
volume = {47},
pages = {253, 279}
}

@inproceedings{Mnih2016,
author = {Mnih, V. and Badia, A. P. and Mirza, M. M and , Grave, A. and , Lillicrap, T and , Harley, T. and Kavukcuoglu, K. },
title = {Asynchronous methods for deep reinforcement learning},
year = {2016},
pages = {1928, 1937}
}

@Article{Yang2018,
  author  = {Yang, X. and Zheng, L. and Zhang, P.},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  title   = {Reinforcement Learning for Portfolio Management: A Framework and Case Study.},
  year    = {2018},
}

@Article{Kober2013,
  author  = {Kober, J. and Bagnell, J. A. and Peters, J. and Liang, X. and Feng, J. and Xiang, S. and Wang, L.},
  journal = {The International Journal of Robotics Research},
  title   = {Reinforcement learning in robotics: A survey},
  year    = {2013},
  number  = {11},
  pages   = {1238, 1274},
  volume  = {32},
  doi     = {10.1109/ACCESS.2018.2858220},
  url     = {https://doi.org/10.1177/0278364913495721},
}

@Article{Zhang,
  author  = {Zhang, Y. and Zhou, D.},
  journal = {IEEE Journal of Biomedical and Health Informatics},
  title   = {Deep reinforcement learning for dynamic treatment regimes on medical registry data},
  number  = {6},
  pages   = {1844, 1856},
  volume  = {22},
  doi     = {10.1109/JBHI.2018.2817565},
  url     = {https://doi.org/10.1109/JBHI.2018.2817565},
}

@Article{Silver,
  author  = {Silver, D. and Schrittwieser, J. and Simonyan, K. and Antonoglou, I. and Huang, A. and Guez, A. and Hassabis, D.},
  journal = {Nature},
  title   = {Mastering the game of go without human knowledge},
  number  = {7676},
  pages   = {354, 359},
  volume  = {550},
  doi     = {10.1038/nature24270},
  url     = {https://doi.org/10.1038/nature24270},
}

@Book{Goodfellow,
  author    = {Goodfellow, I. and Bengio, Y. and Courville, A.},
  publisher = {MIT Press},
  title     = {Deep learning},
}

@InProceedings{Dosovitskiy,
  author    = {Dosovitskiy, A. and Ros, G. and Codevilla, F. and Lopez, A. and Koltun, V.},
  booktitle = {Proceedings of the 1st annual conference on robot rearning},
  title     = {CARLA: An open urban driving simulator},
  pages     = {1, 16},
}

@Article{Brockman,
  author  = {Brockman, G. and Cheung, V. and Pettersson, L. and Schneider, J. and Schulman, J. and Tang, J. and Zaremba, W.},
  journal = {Journal of Artificial Intelligence Research},
  title   = {The arcade learning environment: An evaluation platform for general agents},
  note    = {OpenAI Gym. arXiv preprint arXiv:1606.01540.},
  number  = {1},
  pages   = {253, 279},
  volume  = {47},
  arxiv   = {1606.01540},
  doi     = {10.1613/jair.3912},
  url     = {https://doi.org/10.1613/jair.3912},
}

@Comment{jabref-meta: databaseType:bibtex;}
