@article{anderson2021_threat_hunting,
  author  = {Anderson, B. and McGrew, D.},
  title   = {Machine Learning for Threat Hunting: Techniques and Tools},
  journal = {Journal of Cybersecurity and Privacy},
  year    = {2021},
  volume  = {1},
  number  = {2},
  pages   = {134--156}
}

@inproceedings{lee2020_ai_forensics,
  author    = {Lee, C. and Kim, J.},
  title     = {AI-Driven Digital Forensics: Challenges and Approaches},
  booktitle = {Proceedings of the International Conference on Digital Forensics},
  year      = {2020},
  pages     = {98--112}
}

@article{sommer2010_outliers,
  author  = {Sommer, R. and Paxson, V.},
  title   = {Outside the Closed World: On Using Machine Learning for Network Intrusion Detection},
  journal = {IEEE Symposium on Security and Privacy},
  year    = {2010},
  pages   = {305--316}
}

@article{zhou2019_log_analysis,
  author  = {Zhou, Y. and Leung, H.},
  title   = {Deep Learning Based Log Analysis for Anomaly Detection},
  journal = {Information Sciences},
  year    = {2019},
  volume  = {482},
  pages   = {193--210}
}

@inproceedings{xu2018_deeplog,
  author    = {Xu, W. and Du, X. and Li, Z.},
  title     = {DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning},
  booktitle = {Proceedings of the 2018 ACM Conference on Computer and Communications Security},
  year      = {2018},
  pages     = {1285--1298}
}

@article{han2022_threat_intel,
  author  = {Han, J. and Lee, Y.},
  title   = {Threat Intelligence Integration in Security Information and Event Management Systems},
  journal = {Computers \& Security},
  year    = {2022},
  volume  = {112},
  pages   = {102535}
}

@book{stallings2017_cryptography,
  author    = {Stallings, W.},
  title     = {Cryptography and Network Security: Principles and Practice},
  publisher = {Pearson Education},
  year      = {2017},
  edition   = {7}
}

@article{sharafaldin2018_dataset,
  author  = {Sharafaldin, I. and Lashkari, A. H. and Ghorbani, A. A.},
  title   = {Toward Generating a New Intrusion Detection Dataset and Intrusion Traffic Characterization},
  journal = {Proceedings of the ICISSP 2018},
  year    = {2018},
  pages   = {108--116}
}

@Article{Devlin2019a,
  author = {Devlin, J. and Chang, M.-W. and Lee, K. and Toutanova, K.},
  title  = {BERT: Pre-training of deep bidirectional transformers for language understanding},
  year   = {2019},
  note   = {Preprint arXiv:1810.04805.},
}

@Article{Lee2020a,
  author  = {Lee, J.},
  journal = {Bioinformatics},
  title   = {BioBERT: A pre-trained biomedical language representation model for biomedical text mining},
  year    = {2020},
  pages   = {1234, 1240},
  volume  = {36},
}

@Article{Zhang2015a,
  author    = {Zhang, X. and Zhao, J. and LeCun, Y.},
  journal   = {Advances in Neural Information Processing Systems},
  title     = {Character-level Convolutional Networks for Text Classificatio},
  year      = {2015},
  pages     = {649–657},
  volume    = {28},
  publisher = {NeurIPS},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf},
}

@Article{Sanh2019a,
  author = {Sanh, V. and Debut, L. and Chaumond, J. and Wolf, T.},
  title  = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  year   = {2019},
  note   = {arXiv preprint arXiv:1910.01108},
  url    = {https://arxiv.org/abs/1910.01108/},
}

@Article{Srivastava2014a,
  author  = {Srivastava, N. and Hinton, G. and Krizhevsky, A. and Sutskever, I. and Salakhutdinov, R.},
  journal = {Journal of Machine Learning Research},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  year    = {2014},
  pages   = {1929–1958},
  volume  = {15},
  issue   = {56},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html},
}

@Article{Raffel2020a,
  author = {Raffel, C.},
  title  = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  year   = {2020},
  note   = {Preprint arXiv:1910.10683.},
}

@InProceedings{Pires2019a,
  author       = {Pires, T. and Schlinger, E. and Garrette, D.},
  title        = {How Multilingual is Multilingual BERT?},
  year         = {2019},
  organization = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages        = {4996–5001},
  publisher    = {Association for Computational Linguistics},
  doi          = {DOI: 10.18653/v1/P19-14},
}

@Article{Brown2020a,
  author  = {Brown, T. and Mann, B. and Ryder, N. and Subbiah, M. and Kaplan, J. D. and Dhariwal, P. and Neelakantan, A. and Shyam, P. and Sastry, G. and Askell, A. and Agarwal, S. and Herbert-Voss, A. and Krueger, G. and Henighan, T. and Child, R. and Ramesh, A. and Ziegler, D. M. and Wu, J. and Winter, C. and Amodei, D.},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Language Models are Few-Shot Learners},
  year    = {2020},
  pages   = {1877–1901},
  volume  = {33},
  url     = {https://arxiv.org/abs/2005.14165/},
}

@Article{Chalkidis2020a,
  author = {Chalkidis, I. and Fergadiotis, M. and Malakasiotis, P. and Aletras, N. and Androutsopoulos, I.},
  title  = {LEGAL-BERT: The Muppets straight out of law school},
  year   = {2020},
  note   = {arXiv preprint arXiv:2010.02559/},
  url    = {https://arxiv.org/abs/2010.02559/},
}

@Article{Liu2019a,
  author = {Liu, Y. and Ott, M. and Goyal, N. and Du, J. and Joshi, M. and Chen, D. and Levy, O. and Lewis, M. and Zettlemoyer, L. and Stoyanov, V.},
  title  = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  year   = {2019},
  note   = {arXiv preprint arXiv:1907.11692},
  url    = {https://arxiv.org/abs/1907.11692/},
}

@InProceedings{Ruder2019a,
  author       = {Ruder, S. and Peters, M. E. and Swayamdipta, S. and Wolf, T.},
  booktitle    = {Proceedings of NAACL 2019 Tutorial},
  title        = {Transfer Learning in NLP},
  year         = {2019},
  organization = {Proceedings of NAACL 2019 Tutorial},
}

@Article{Howard2018a,
  author = {Howard, J. and Ruder, S.},
  title  = {Universal language model fine-tuning for text classification},
  year   = {2018},
  note   = {Preprint arXiv:1801.06146.},
}

@Article{Conneau2020a,
  author = {Conneau, A.},
  title  = {Unsupervised cross-lingual representation learning at scale},
  year   = {2020},
  note   = {Preprint arXiv:1911.02116.},
}

@InProceedings{Brown2020b,
  author    = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Language Models are Few-Shot Learners},
  year      = {2020},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {1877--1901},
  publisher = {Curran Associates, Inc.},
  volume    = {33},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
