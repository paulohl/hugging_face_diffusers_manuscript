<?xml version="1.0"?>
<b:Sources SelectedStyle="" xmlns:b="http://schemas.openxmlformats.org/officeDocument/2006/bibliography" xmlns="http://schemas.openxmlformats.org/officeDocument/2006/bibliography"><b:Source>
		<b:Year>2019</b:Year>
		<b:BIBTEX_Entry>article</b:BIBTEX_Entry>
		<b:Comments>Preprint arXiv:1810.04805.</b:Comments>
		<b:SourceType>JournalArticle</b:SourceType>
		<b:Title>BERT: Pre-training of deep bidirectional transformers for language understanding</b:Title>
		<b:Tag>Devlin2019</b:Tag>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Devlin</b:Last>
						<b:First>J.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Chang</b:Last>
						<b:First>M.-W.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Lee</b:Last>
						<b:First>K.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Toutanova</b:Last>
						<b:First>K.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:RefOrder>3</b:RefOrder></b:Source><b:Source>
		<b:Volume>36</b:Volume>
		<b:BIBTEX_Entry>article</b:BIBTEX_Entry>
		<b:SourceType>JournalArticle</b:SourceType>
		<b:Title>BioBERT: A pre-trained biomedical language representation model for biomedical text mining</b:Title>
		<b:Tag>Lee2020</b:Tag>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Lee</b:Last>
						<b:First>J.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:Pages>1234, 1240</b:Pages>
		<b:Year>2020</b:Year>
		<b:JournalName>Bioinformatics</b:JournalName>
		<b:Number>4</b:Number>
		<b:RefOrder>5</b:RefOrder></b:Source><b:Source><b:Tag>Zha15</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{F61F419F-61B5-4B85-BD66-53B78A752E43}</b:Guid><b:Title>Character-level Convolutional Networks for Text Classificatio</b:Title><b:JournalName> Advances in Neural Information Processing Systems</b:JournalName><b:Year>2015</b:Year><b:Pages>649–657</b:Pages><b:Volume>28</b:Volume><b:Author><b:Author><b:NameList><b:Person><b:Last>Zhang</b:Last><b:First>X</b:First></b:Person><b:Person><b:First>Zhao,</b:First><b:Middle>J.</b:Middle></b:Person><b:Person><b:Last>LeCun</b:Last><b:First>Y.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Publisher>NeurIPS</b:Publisher><b:URL>https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf</b:URL><b:RefOrder>12</b:RefOrder></b:Source><b:Source><b:Tag>San19</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{5E8B4155-2955-468F-BF87-D4EE789AB4FE}</b:Guid><b:Title>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</b:Title><b:Year>2019</b:Year><b:Author><b:Author><b:NameList><b:Person><b:Last>Sanh</b:Last><b:First>V</b:First></b:Person><b:Person><b:First>Debut,</b:First><b:Middle>L.</b:Middle></b:Person><b:Person><b:Last>Chaumond</b:Last><b:First>J.</b:First></b:Person><b:Person><b:Last>Wolf</b:Last><b:First>T.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Comments>arXiv preprint arXiv:1910.01108</b:Comments><b:URL>https://arxiv.org/abs/1910.01108/</b:URL><b:RefOrder>9</b:RefOrder></b:Source><b:Source><b:Tag>Sri14</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{4E7EDD00-2246-42DD-9EF1-A28859DF2708}</b:Guid><b:Title>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</b:Title><b:JournalName>Journal of Machine Learning Research</b:JournalName><b:Year>2014</b:Year><b:Pages>1929–1958</b:Pages><b:Volume>15</b:Volume><b:Issue>56</b:Issue><b:Author><b:Author><b:NameList><b:Person><b:Last>Srivastava</b:Last><b:First>N.</b:First></b:Person><b:Person><b:Last>Hinton</b:Last><b:First>G.</b:First></b:Person><b:Person><b:Last>Krizhevsky</b:Last><b:First>A.</b:First></b:Person><b:Person><b:Last>Sutskever</b:Last><b:First>I.</b:First></b:Person><b:Person><b:Last>Salakhutdinov</b:Last><b:First>R.</b:First></b:Person></b:NameList></b:Author></b:Author><b:URL>http://jmlr.org/papers/v15/srivastava14a.html</b:URL><b:RefOrder>11</b:RefOrder></b:Source><b:Source>
		<b:Year>2020</b:Year>
		<b:BIBTEX_Entry>article</b:BIBTEX_Entry>
		<b:Comments>Preprint arXiv:1910.10683.</b:Comments>
		<b:SourceType>JournalArticle</b:SourceType>
		<b:Title>Exploring the limits of transfer learning with a unified text-to-text transformer</b:Title>
		<b:Tag>Raffel2020</b:Tag>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Raffel</b:Last>
						<b:First>C.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:RefOrder>4</b:RefOrder></b:Source><b:Source><b:Tag>Pir19</b:Tag><b:SourceType>ConferenceProceedings</b:SourceType><b:Guid>{164C5B9E-D076-4F37-8A9F-BDE22118E929}</b:Guid><b:Title>How Multilingual is Multilingual BERT?</b:Title><b:Year>2019</b:Year><b:Publisher>Association for Computational Linguistics</b:Publisher><b:Pages>4996–5001</b:Pages><b:ConferenceName>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</b:ConferenceName><b:Author><b:Author><b:NameList><b:Person><b:Last>Pires</b:Last><b:First>T.</b:First></b:Person><b:Person><b:Last>Schlinger</b:Last><b:First>E.</b:First></b:Person><b:Person><b:Last>Garrette</b:Last><b:First>D.</b:First></b:Person></b:NameList></b:Author></b:Author><b:DOI>DOI: 10.18653/v1/P19-14</b:DOI><b:RefOrder>7</b:RefOrder></b:Source><b:Source><b:Tag>Bro20</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{8B64C654-2B63-4E1D-AC1B-8C4E16B53B66}</b:Guid><b:Title>Language Models are Few-Shot Learners</b:Title><b:Year>2020</b:Year><b:Pages>1877–1901</b:Pages><b:Volume>33</b:Volume><b:URL>https://arxiv.org/abs/2005.14165/</b:URL><b:Author><b:Author><b:NameList><b:Person><b:Last>Brown</b:Last><b:First>T.</b:First></b:Person><b:Person><b:Last>Mann</b:Last><b:First>B.</b:First></b:Person><b:Person><b:Last>Ryder</b:Last><b:First>N.</b:First></b:Person><b:Person><b:Last>Subbiah</b:Last><b:First>M.</b:First></b:Person><b:Person><b:Last>Kaplan</b:Last><b:First>J.</b:First><b:Middle>D.</b:Middle></b:Person><b:Person><b:Last>Dhariwal</b:Last><b:First>P.</b:First></b:Person><b:Person><b:Last>Neelakantan</b:Last><b:First>A.</b:First></b:Person><b:Person><b:Last>Shyam</b:Last><b:First>P.</b:First></b:Person><b:Person><b:Last>Sastry</b:Last><b:First>G.</b:First></b:Person><b:Person><b:Last>Askell</b:Last><b:First>A.</b:First></b:Person><b:Person><b:Last>Agarwal</b:Last><b:First>S.</b:First></b:Person><b:Person><b:Last>Herbert-Voss</b:Last><b:First>A.</b:First></b:Person><b:Person><b:Last>Krueger</b:Last><b:First>G.</b:First></b:Person><b:Person><b:Last>Henighan</b:Last><b:First>T.</b:First></b:Person><b:Person><b:Last>Child</b:Last><b:First>R.</b:First></b:Person><b:Person><b:Last>Ramesh</b:Last><b:First>A.</b:First></b:Person><b:Person><b:Last>Ziegler</b:Last><b:First>D.</b:First><b:Middle>M.</b:Middle></b:Person><b:Person><b:Last>Wu</b:Last><b:First>J.</b:First></b:Person><b:Person><b:Last>Winter</b:Last><b:First>C.</b:First></b:Person><b:Person><b:Last>Amodei</b:Last><b:First>D.</b:First></b:Person></b:NameList></b:Author></b:Author><b:JournalName>Advances in Neural Information Processing Systems</b:JournalName><b:RefOrder>8</b:RefOrder></b:Source><b:Source><b:Tag>Cha20</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{3977D541-3C72-43B0-BD45-17D2777D9035}</b:Guid><b:Title>LEGAL-BERT: The Muppets straight out of law school</b:Title><b:Year>2020</b:Year><b:Author><b:Author><b:NameList><b:Person><b:Last>Chalkidis</b:Last><b:First>I.</b:First></b:Person><b:Person><b:Last>Fergadiotis</b:Last><b:First>M.</b:First></b:Person><b:Person><b:Last>Malakasiotis</b:Last><b:First>P.</b:First></b:Person><b:Person><b:Last>Aletras</b:Last><b:First>N.</b:First></b:Person><b:Person><b:Last>Androutsopoulos</b:Last><b:First>I.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Comments>arXiv preprint arXiv:2010.02559/</b:Comments><b:URL>https://arxiv.org/abs/2010.02559/</b:URL><b:RefOrder>10</b:RefOrder></b:Source><b:Source><b:Tag>Liu19</b:Tag><b:SourceType>JournalArticle</b:SourceType><b:Guid>{93710E1E-04AF-40B3-91C2-46049194FE99}</b:Guid><b:Author><b:Author><b:NameList><b:Person><b:Last>Liu</b:Last><b:First>Y.</b:First></b:Person><b:Person><b:Last>Ott</b:Last><b:First>M.</b:First></b:Person><b:Person><b:Last>Goyal</b:Last><b:First>N.</b:First></b:Person><b:Person><b:Last>Du</b:Last><b:First>J.</b:First></b:Person><b:Person><b:Last>Joshi</b:Last><b:First>M.</b:First></b:Person><b:Person><b:Last>Chen</b:Last><b:First>D.</b:First></b:Person><b:Person><b:Last>Levy</b:Last><b:First>O.</b:First></b:Person><b:Person><b:Last>Lewis</b:Last><b:First>M.</b:First></b:Person><b:Person><b:Last>Zettlemoyer</b:Last><b:First>L.</b:First></b:Person><b:Person><b:Last>Stoyanov</b:Last><b:First>V.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Title>RoBERTa: A Robustly Optimized BERT Pretraining Approach</b:Title><b:Year>2019</b:Year><b:Comments>arXiv preprint arXiv:1907.11692</b:Comments><b:URL>https://arxiv.org/abs/1907.11692/</b:URL><b:RefOrder>13</b:RefOrder></b:Source><b:Source>
		<b:Year>2019</b:Year>
		<b:BIBTEX_Entry>proceedings</b:BIBTEX_Entry>
		<b:SourceType>ConferenceProceedings</b:SourceType>
		<b:Title>Transfer Learning in NLP</b:Title>
		<b:Tag>Ruder2019</b:Tag>
		<b:BookTitle>Proceedings of NAACL 2019 Tutorial</b:BookTitle>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Ruder</b:Last>
						<b:First>S.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Peters</b:Last>
						<b:Middle>E.</b:Middle>
						<b:First>M.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Swayamdipta</b:Last>
						<b:First>S.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Wolf</b:Last>
						<b:First>T.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:ConferenceName>Proceedings of NAACL 2019 Tutorial</b:ConferenceName>
		<b:RefOrder>1</b:RefOrder></b:Source><b:Source>
		<b:Year>2018</b:Year>
		<b:BIBTEX_Entry>article</b:BIBTEX_Entry>
		<b:Comments>Preprint arXiv:1801.06146.</b:Comments>
		<b:SourceType>JournalArticle</b:SourceType>
		<b:Title>Universal language model fine-tuning for text classification</b:Title>
		<b:Tag>Howard2018</b:Tag>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Howard</b:Last>
						<b:First>J.</b:First>
					</b:Person>
					<b:Person>
						<b:Last>Ruder</b:Last>
						<b:First>S.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:RefOrder>2</b:RefOrder></b:Source><b:Source>
		<b:Year>2020</b:Year>
		<b:BIBTEX_Entry>article</b:BIBTEX_Entry>
		<b:Comments>Preprint arXiv:1911.02116.</b:Comments>
		<b:SourceType>JournalArticle</b:SourceType>
		<b:Title>Unsupervised cross-lingual representation learning at scale</b:Title>
		<b:Tag>Conneau2020</b:Tag>
		<b:Author>
			<b:Author>
				<b:NameList>
					<b:Person>
						<b:Last>Conneau</b:Last>
						<b:First>A.</b:First>
					</b:Person>
				</b:NameList>
			</b:Author>
		</b:Author>
		<b:RefOrder>6</b:RefOrder></b:Source></b:Sources>
